# STATS 607 Final Project: Accelerating OPE for Confounded POMDPs
This repo reproduces the simulation setting from the NeurIPS 2022 paper on off-policy evaluation (OPE) in episodic POMDPs under nonparametric models, and focuses on an optimized implementation.

The core estimator is a **sequential** FQE-style recursion with minimax estimation of NPIV problems at each time step. The recursion over time `t` is preserved. The implementation emphasizes engineering improvements for speed and usability: vectorized trajectory collection, more stable RKHS linear algebra, cross-platform sweep scripts, and optional CPU parallelization over random seeds.

## Repository layout

- `ContSimuOffPolicy.py`  
  Main entry point for a single configuration `(T, n, epsilon)` and `n_sims` seeds. Produces a CSV with per-seed outputs.
- `scripts/run_grid.py`  
  Cross-platform sweep runner for the two experiment modes (A and B). Writes tables into `results/tables/`.
- `scripts/plot_results.py`  
  Produces publication-style **4-panel** figures for Mode A and Mode B and writes them into `results/figures/`.
- `results/tables/`  
  Output CSV tables (`ResultA.csv`, `ResultB.csv`, and demo CSVs).
- `results/figures/`  
  Output figures (PDF/PNG).

## Project structure

```text
POMDP/
  results/
   - tables/               # CSV outputs (ResultA.csv, ResultB.csv, demo.csv, ...)
   - figures/              # Figures generated by scripts/plot_results.py
  scripts/
   - run_grid.py           # Run Mode A/B sweeps and write results/tables/*.csv
   - plot_results.py       # Create 4-panel figures from results/tables/*.csv
   - demo_sweep.py         # The scripts for a demo. Run by demo_sweep.cmd
  agents.py                # Policy base class used by ContPolicy in ContSimuOffPolicy.py
  .gitignore               # gitignore file
  ContSimuOffPolicy.py     # Main entry point: run one (T,n,epsilon) job over n_sims seeds
  envs.py                  # Confounded continuous POMDP environment (Gymnasium-style API)
  demo_sweep.cmd           # Run a demo
  prox_fqe.py              # Sequential FQE recursion with NPIV regression at each step
  rkhs_torch.py            # NPIV solver (stable linear algebra + kernel utilities)
  utils.py                 # Vectorized data collection, MC evaluator, seeding utilities
  requirements.txt         # Python dependencies (`pip install -r requirements.txt`)
  README.md                # Project instructions and usage
  report-WEI.pdf           # Final report by Ziheng Wei
```


## Environment setup (Windows, venv + pip)

1) Create and activate a virtual environment:

```bat
python -m venv .venv
.\.venv\Scripts\activate
python -m pip install -U pip setuptools wheel
```

2) Install PyTorch with CUDA:

```bat
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126
```

3) Install the remaining dependencies from `requirements.txt`:

```bat
pip install -r requirements.txt
```

4) Quick check:

```bat
python -c "import torch; import gymnasium; print(torch.__version__); print(torch.cuda.is_available())"
```

## Quick demo 

```bat
python ContSimuOffPolicy.py --T 4 --n 64 --epsilon 0.2 --device cuda:0 --mc-episodes 200 --eval-initial 200 --n-sims 2 --out results\tables\demo.csv
```

Output: `results/tables/demo.csv` with columns
`episode_len, samp_size, epsilon, seed, abs_error, value_hat, true_value, fit_sec`.

## Full sweep (Mode A + Mode B)

**Mode A (horizon sweep):** fix the offline sample size at `n=512` and vary the horizon `T` to study how estimation error and runtime change with longer planning horizons.  
**Mode B (sample-size sweep):** fix `T ∈ {1,3,5}` and vary the offline sample size `n` to study statistical scaling with more data at short horizons.


### Option 1: GPU, no parallelization
```bat
python scripts\run_grid.py --mode AB --device cuda:0 --epsilon 0.2 --mc-episodes 50000 --eval-initial 10000 --n-sims 100 --out-root results --quiet
```

### Option 2: CPU, parallelization
```bat
set POMDP_N_WORKERS=4 && python scripts\run_grid.py --mode AB --device cpu --epsilon 0.2 --mc-episodes 50000 --eval-initial 10000 --n-sims 100 --out-root results --quiet
```
This parallelizes seeds inside each (T, n) job.

Recommended: 2–6 workers depending on your CPU.

Outputs:
- `results/tables/ResultA.csv`
- `results/tables/ResultB.csv`

## Plotting

```bat
python scripts\plot_results.py --out-root results
```

Outputs:
- `results/figures/fig_modeA_4panel.png`
- `results/figures/fig_modeB_4panel.png`

Optional flags:
- Disable confidence bands: `--no-band`
- Save PNG: `--fmt png --dpi 300`


## Example
This example runs a CPU sweep (Mode A + Mode B) with parallelization over seeds, then generates the two 4-panel figures.

### Step 1: Environment Setup

See the Section: **Environment Setup**.

### Step 2: Run the demo sweep script
Run the following code:
```bat
demo_sweep.cmd
```
### Expected outputs

Tables:

`results\tables\ResultA.csv`

`results\tables\ResultB.csv`

Figures:

`results\figures\fig_modeA_4panel.png`

`results\figures\fig_modeB_4panel.png`



## Notes

- mc-episodes controls Monte Carlo episodes used to estimate the true policy value (cached under `.cache_pomdp/`).
- eval-initial controls how many initial states are sampled to evaluate the fitted value function.
- GPU runs are single-process by default; CPU runs can parallelize over seeds using `POMDP_N_WORKERS`.
